![VRChat-to-BLIP](https://github.com/Vinventive/VRChat-to-BLIP/assets/91992989/2decd6cc-48c4-453e-9225-3b2a73ab7f70)
# VRChat-to-BLIP
VRChat-to-BLIP can process visual data from VRChat to generate captions that describe the scene and objects. When paired with another large language model, this will offer new possibilities for interactability, enhanced cognitive capability and accessibility within virtual environments.

> [!NOTE]
> All code within my repository is either under development, in an experimental state, or postponed. It exclusively supports Windows and was tested using high-end PC workstations equipped with NVIDIA GPUs (approximately 24GB VRAM), and CPUs (around 16 cores) with 64GB RAM. All my repositories are licensed under the MIT License. Feel free to fork and further develop them. However, ensure that your system hardware is compatible with the requirements of a high-end workstation PC to effectively run the code.
